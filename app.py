import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import io
from huggingface_hub import hf_hub_download
from models import (
    UNet, 
    DeepLabV3Plus,
    predict_mask
)
from scipy.spatial import distance
# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å†°æ¹–åˆ†å‰²ç³»ç»Ÿ",
    page_icon="ğŸŒŠ",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
    .main {
        padding: 2rem;
    }
    .stButton>button {
        width: 100%;
        height: 3em;
        margin-top: 1em;
    }
    .upload-box {
        border: 2px dashed #4CAF50;
        border-radius: 10px;
        padding: 20px;
        text-align: center;
    }
    .result-box {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 10px;
        margin-top: 10px;
    }
    .header-container {
        text-align: center;
        padding: 1rem;
        background-color: #f0f2f6;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    </style>
    """, unsafe_allow_html=True)

@st.cache_resource
def load_models():
    """åŠ è½½æ¨¡å‹"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    try:
        # åŠ è½½UNetæ¨¡å‹
        unet_model = UNet()
        model_path_1 = hf_hub_download(
            repo_id = "yuyue231300/glacial_lake_model",
            filename = 'best_model_unet.pth'
        )
        unet_state = torch.load(model_path_1, map_location=device)
        if 'model_state_dict' in unet_state:
            unet_model.load_state_dict(unet_state['model_state_dict'])
        else:
            unet_model.load_state_dict(unet_state)
        unet_model.to(device)
        unet_model.eval()
        
        # åŠ è½½DeepLabV3+æ¨¡å‹
        deeplabv3_model = DeepLabV3Plus()
        model_path = hf_hub_download(
            repo_id="yuyue231300/glacial_lake_model",
            filename="best_model_deeplabv3plus.pth"  # ä½ çš„æ¨¡å‹æ–‡ä»¶å
        )
        deeplabv3_state = torch.load(model_path, map_location=device)
        if 'model_state_dict' in deeplabv3_state:
            deeplabv3_model.load_state_dict(deeplabv3_state['model_state_dict'])
        else:
            deeplabv3_model.load_state_dict(deeplabv3_state)
        deeplabv3_model.to(device)
        deeplabv3_model.eval()
        
        return unet_model, deeplabv3_model, device
        
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½é”™è¯¯: {str(e)}")
        raise e

@st.cache_data
def load_sample_image():
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡"""
    return Image.open('demo.png')

def overlay_mask(image, mask, alpha=0.5):
    """å°†åˆ†å‰²æ©ç å åŠ åˆ°åŸå§‹å›¾åƒä¸Š"""
    if isinstance(image, Image.Image):
        image = np.array(image)
    
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    elif image.shape[2] == 4:
        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
    
    mask_colored = np.zeros_like(image)
    mask_colored[mask > 128] = [0, 255, 0]
    
    overlay = cv2.addWeighted(image, 1, mask_colored, alpha, 0)
    return overlay

def analyze_all_lakes(mask, pixel_size=1, min_area=100):
    """åˆ†ææ‰€æœ‰å†°æ¹–
    Args:
        mask: äºŒå€¼åŒ–æ©ç å›¾åƒ
        pixel_size: æ¯ä¸ªåƒç´ ä»£è¡¨çš„å®é™…å¤§å°ï¼ˆç±³ï¼‰
        min_area: æœ€å°é¢ç§¯é˜ˆå€¼ï¼Œè¿‡æ»¤æ‰å¤ªå°çš„åŒºåŸŸ
    Returns:
        list: åŒ…å«æ‰€æœ‰å†°æ¹–çš„æŒ‡æ ‡
    """
    # ç¡®ä¿æ©ç æ˜¯äºŒå€¼å›¾åƒ
    binary_mask = (mask > 128).astype(np.uint8)
    
    # æ‰¾åˆ°æ‰€æœ‰è½®å»“
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    lakes = []
    for idx, contour in enumerate(contours, 1):
        # è®¡ç®—é¢ç§¯å¹¶è¿‡æ»¤å°åŒºåŸŸ
        area_pixels = cv2.contourArea(contour)
        if area_pixels < min_area:
            continue
            
        # è®¡ç®—å®é™…é¢ç§¯
        area = area_pixels * (pixel_size ** 2)
        
        # è·å–æœ€å°å¤–æ¥çŸ©å½¢
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        
        # è®¡ç®—é•¿åº¦å’Œå®½åº¦
        width = rect[1][0] * pixel_size
        length = rect[1][1] * pixel_size
        
        # ç¡®ä¿é•¿åº¦å¤§äºå®½åº¦
        if width > length:
            width, length = length, width
        
        # è®¡ç®—é•¿å®½æ¯”
        aspect_ratio = length / width if width > 0 else 0
        
        # è®¡ç®—å‘¨é•¿
        perimeter = cv2.arcLength(contour, True) * pixel_size
        
        # è®¡ç®—è´¨å¿ƒ
        M = cv2.moments(contour)
        if M['m00'] != 0:
            cx = int(M['m10'] / M['m00'])
            cy = int(M['m01'] / M['m00'])
        else:
            cx, cy = 0, 0
        
        lakes.append({
            'id': idx,
            'area': area,
            'length': length,
            'width': width,
            'aspect_ratio': aspect_ratio,
            'perimeter': perimeter,
            'contour': contour,
            'box': box,
            'centroid': (cx, cy)
        })
    
    # æŒ‰é¢ç§¯é™åºæ’åº
    lakes.sort(key=lambda x: x['area'], reverse=True)
    return lakes

def draw_lakes_visualization(image, lakes):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ‰€æœ‰å†°æ¹–çš„æ ‡è¯†å’Œæµ‹é‡ç»“æœ"""
    # åˆ›å»ºå›¾åƒå‰¯æœ¬
    result = image.copy()
    if isinstance(result, np.ndarray) and len(result.shape) == 2:
        result = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)
    
    # åˆ›å»ºä¸åŒé¢œè‰²çš„å¾ªç¯
    colors = [
        (255, 0, 0),   # çº¢
        (0, 255, 0),   # ç»¿
        (0, 0, 255),   # è“
        (255, 255, 0), # é»„
        (255, 0, 255), # ç´«
        (0, 255, 255), # é’
    ]
    
    for i, lake in enumerate(lakes):
        color = colors[i % len(colors)]
        
        # ç»˜åˆ¶è½®å»“
        cv2.drawContours(result, [lake['contour']], 0, color, 2)
        
        # ç»˜åˆ¶æ¹–æ³Šç¼–å·
        cv2.putText(
            result,
            f"#{lake['id']}", 
            lake['centroid'],
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            color,
            1
        )
    
    return result
def main():
    st.markdown("""
        <div class="header-container">
            <h1>ğŸŒŠ å†°æ¹–åˆ†å‰²ç³»ç»Ÿ</h1>
            <p>ä½¿ç”¨æ·±åº¦å­¦ä¹ å®ç°å†°æ¹–åŒºåŸŸè‡ªåŠ¨åˆ†å‰²</p>
        </div>
    """, unsafe_allow_html=True)
    
    try:
        # åŠ è½½æ¨¡å‹
        unet_model, deeplabv3_model, device = load_models()
        models_loaded = True
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        models_loaded = False
        return
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    # å·¦ä¾§åˆ—ï¼šæ¨¡å‹é€‰æ‹©å’Œå›¾ç‰‡ä¸Šä¼ 
    with col1:
        st.subheader("é…ç½®")
        
        # æ¨¡å‹é€‰æ‹©
        model_type = st.radio(
            "é€‰æ‹©æ¨¡å‹",
            ("UNet", "DeepLabV3+"),
            help="é€‰æ‹©è¦ä½¿ç”¨çš„åˆ†å‰²æ¨¡å‹"
        )
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ å›¾ç‰‡",
            type=['jpg', 'jpeg', 'png'],
            help="æ”¯æŒjpgã€jpegã€pngæ ¼å¼çš„å›¾ç‰‡"
        )
        
        # ç¤ºä¾‹å›¾ç‰‡æŒ‰é’®
        if st.button("ä½¿ç”¨ç¤ºä¾‹å›¾ç‰‡"):
            st.session_state['use_sample'] = True
            
        # è·å–è¦å¤„ç†çš„å›¾ç‰‡
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')
        elif st.session_state.get('use_sample', False):
            image = load_sample_image()
        else:
            st.info("è¯·ä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨ç¤ºä¾‹å›¾ç‰‡")
            return
            
        # æ˜¾ç¤ºåŸå§‹å›¾ç‰‡ä¿¡æ¯
        st.markdown("### å›¾ç‰‡ä¿¡æ¯")
        st.write(f"åŸå§‹å°ºå¯¸: {image.size[0]} Ã— {image.size[1]} åƒç´ ")
            # æ·»åŠ ä½¿ç”¨è¯´æ˜
        st.markdown("---")
        with st.expander("ä½¿ç”¨è¯´æ˜"):
            st.markdown("""
            ### ä½¿ç”¨æ­¥éª¤
            1. åœ¨å·¦ä¾§é€‰æ‹©è¦ä½¿ç”¨çš„åˆ†å‰²æ¨¡å‹ï¼ˆUNetæˆ–DeepLabV3+ï¼‰
            2. ä¸Šä¼ å¾…åˆ†æçš„å›¾ç‰‡æˆ–ä½¿ç”¨ç¤ºä¾‹å›¾ç‰‡
            3. ä¸Šä¼ å›¾ç‰‡å¯ä»¥ä½¿ç”¨å¤©åœ°å›¾è¿›è¡Œä¸‹è½½ï¼Œä¸‹è½½ä¹‹åå¯ä»¥å¾—åˆ°åƒç´ å¯¹åº”çš„å®é™…è·ç¦»ï¼Œä¾¿äºå¾—åˆ°å‡†ç¡®çš„å†°æ¹–é¢ç§¯å’Œå‘¨é•¿
            4. ç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œåˆ†å‰²å¹¶æ˜¾ç¤ºç»“æœ
            5. å¯¹æ‰€æœ‰å†°æ¹–è¿›è¡Œåˆ†å‰²ï¼Œå¹¶ç»™å‡ºå¤§äºæœ€å°é¢ç§¯çš„å†°æ¹–çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬é¢ç§¯ï¼Œå‘¨é•¿ï¼Œé•¿åº¦ï¼Œå®½åº¦å’Œé•¿å®½æ¯”
            6. å¯ä»¥ä¸‹è½½åˆ†å‰²æ©ç ã€å åŠ æ•ˆæœå’Œå†°æ¹–æµ‹é‡ç»“æœ
        
            ### æ³¨æ„äº‹é¡¹
            - æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼šJPGã€JPEGã€PNG
            - å»ºè®®ä¸Šä¼ æ¸…æ™°çš„å†°æ¹–å›¾ç‰‡ä»¥è·å¾—æœ€ä½³æ•ˆæœ
            - å¤„ç†å¤§å›¾ç‰‡æ—¶è¯·è€å¿ƒç­‰å¾…
            - ä¸åŒæ¨¡å‹å¯èƒ½é€‚ç”¨äºä¸åŒç±»å‹çš„å†°æ¹–ï¼Œå¯ä»¥å°è¯•ä¸åŒæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ•ˆæœ
        
            ### æ¨¡å‹è¯´æ˜
            - **UNet**: ç»å…¸çš„å›¾åƒåˆ†å‰²æ¨¡å‹ï¼Œé€‚åˆè¾¹ç¼˜ç»†èŠ‚çš„æå–
            - **DeepLabV3+**: æ”¹è¿›çš„åˆ†å‰²æ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„è¯­ä¹‰ç†è§£èƒ½åŠ›
            """)
    with col2:
        st.subheader("åˆ†å‰²ç»“æœ")
        
        if models_loaded and 'image' in locals():
            model = unet_model if model_type == "UNet" else deeplabv3_model
            
            # æ·»åŠ æœ€å°é¢ç§¯é˜ˆå€¼è®¾ç½®
            min_area = st.slider(
                "æœ€å°å†°æ¹–é¢ç§¯ (åƒç´ )",
                min_value=10,
                max_value=1000,
                value=100,
                help="è¿‡æ»¤æ‰å°äºæ­¤é¢ç§¯çš„åŒºåŸŸ"
            )
            
            # æ·»åŠ åƒç´ å°ºå¯¸è®¾ç½®
            pixel_size = st.number_input(
                "åƒç´ å®é™…å¤§å°ï¼ˆç±³ï¼‰",
                min_value=0.1,
                value=1.0,
                help="è®¾ç½®æ¯ä¸ªåƒç´ ä»£è¡¨çš„å®é™…è·ç¦»ï¼ˆç±³ï¼‰"
            )
            
            with st.spinner('æ­£åœ¨è¿›è¡Œå›¾åƒåˆ†å‰²å’Œåˆ†æ...'):
                mask = predict_mask(model, image, device)
                overlay = overlay_mask(image, mask)
                
                # åˆ†ææ‰€æœ‰å†°æ¹–
                lakes = analyze_all_lakes(mask, pixel_size, min_area)
                
                # ç»˜åˆ¶å¯è§†åŒ–ç»“æœ
                lakes_viz = draw_lakes_visualization(np.array(image), lakes)
            
            # æ˜¾ç¤ºç»“æœ
            tabs = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†å‰²æ©ç ", "å åŠ æ•ˆæœ", "å†°æ¹–æ ‡è¯†"])
            
            with tabs[0]:
                st.image(image, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)
            
            with tabs[1]:
                st.image(mask, caption="åˆ†å‰²æ©ç ", use_container_width=True)
            
            with tabs[2]:
                st.image(overlay, caption="å åŠ æ•ˆæœ", use_container_width=True)
                
            with tabs[3]:
                st.image(lakes_viz, caption="å†°æ¹–æ ‡è¯†", use_container_width=True)
            
            # æ˜¾ç¤ºæ‰€æœ‰å†°æ¹–çš„è¯¦ç»†ä¿¡æ¯
            st.markdown("### æ‰€æœ‰å†°æ¹–æµ‹é‡ç»“æœ")
            
            # åˆ›å»ºæ•°æ®è¡¨æ ¼
            lakes_data = []
            for lake in lakes:
                lakes_data.append({
                    "å†°æ¹–ç¼–å·": f"#{lake['id']}",
                    "é¢ç§¯ (ã¡)": f"{lake['area']:.2f}",
                    "å‘¨é•¿ (m)": f"{lake['perimeter']:.2f}",
                    "é•¿åº¦ (m)": f"{lake['length']:.2f}",
                    "å®½åº¦ (m)": f"{lake['width']:.2f}",
                    "é•¿å®½æ¯”": f"{lake['aspect_ratio']:.2f}"
                })
            
            # æ˜¾ç¤ºè¡¨æ ¼
            st.dataframe(
                lakes_data,
                width=None,
                height=None,
                use_container_width=True
            )
            
            # æ·»åŠ æ•°æ®ä¸‹è½½æŒ‰é’®
            import pandas as pd
            csv = pd.DataFrame(lakes_data).to_csv(index=False)
            st.download_button(
                "ä¸‹è½½æµ‹é‡ç»“æœ",
                csv,
                "lakes_measurements.csv",
                "text/csv",
                key='download-csv'
            )
            
            col6, col7 = st.columns(2)
            
            with col6:
                # ä¿å­˜æ©ç ä¸ºbytes
                mask_bytes = io.BytesIO()
                Image.fromarray(mask).save(mask_bytes, format='PNG')
                st.download_button(
                    label="ä¸‹è½½æ©ç ",
                    data=mask_bytes.getvalue(),
                    file_name="segmentation_mask.png",
                    mime="image/png"
                )
            
            with col7:
                # ä¿å­˜å åŠ æ•ˆæœä¸ºbytes
                overlay_bytes = io.BytesIO()
                Image.fromarray(overlay).save(overlay_bytes, format='PNG')
                st.download_button(
                    label="ä¸‹è½½å åŠ æ•ˆæœ",
                    data=overlay_bytes.getvalue(),
                    file_name="overlay_result.png",
                    mime="image/png"
                )

            # æ·»åŠ é¢ç§¯åˆ†å¸ƒå¯è§†åŒ–
            if len(lakes) > 1:
                st.markdown("### å†°æ¹–é¢ç§¯åˆ†å¸ƒ")
                import plotly.express as px
                
                areas_df = pd.DataFrame([
                    {"å†°æ¹–ç¼–å·": f"#{lake['id']}", "é¢ç§¯": lake['area']}
                    for lake in lakes
                ])
                
                fig = px.bar(
                    areas_df,
                    x="å†°æ¹–ç¼–å·",
                    y="é¢ç§¯",
                    title="å†°æ¹–é¢ç§¯åˆ†å¸ƒ"
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # st.markdown("### å½¢çŠ¶åˆ†æ")
            # shape_metrics = []
            # for lake in lakes:
            #     # è®¡ç®—åœ†å½¢åº¦
            #     circularity = 4 * np.pi * lake['area'] / (lake['perimeter'] ** 2)
            #     shape_metrics.append({
            #         "å†°æ¹–ç¼–å·": f"#{lake['id']}",
            #         "åœ†å½¢åº¦": f"{circularity:.3f}"
            #     })
            
            # st.dataframe(
            #     shape_metrics,
            #     width=None,
            #     height=None,
            #     use_container_width=True
            # )
    
if __name__ == "__main__":
    main()